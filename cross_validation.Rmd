---
title: "Cross Validation"
date: "November 12, 2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
library(mgcv)

set.seed(1)
```

## Cross validation 

```{r}
nonlin_df = 
  tibble(
    id = 1:100,
    x = runif(100, 0, 1),
    y = 1 - 10 * (x - .3) ^ 2 + rnorm(100, 0, .3)
  )

nonlin_df %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + theme_bw()
```

Training and testing

Cross validation by hand 

```{r}
train_df = sample_frac(nonlin_df, size = .8)
test_df = anti_join(nonlin_df, train_df, by = "id")

ggplot(train_df, aes(x = x, y = y)) + 
  geom_point() + 
  geom_point(data = test_df, color = "red")
```

Fit three models of varying goodness:

* Linear regression, which generally doesn't work as well

* Smooth curve

* Wiggly model 

```{r}
linear_mod = lm(x ~ x, data = train_df)
smooth_mod = mgcv::gam(y ~ s(x), data = train_df)
wiggly_mod = mgcv::gam(y ~ s(x, k = 30), sp = 10e-6, data = train_df)
```

Let's look at some fits.

```{r}
train_df %>%
  add_predictions(linear_mod) %>%
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  geom_point(aes(y = pred), color = "red")

train_df %>%
  add_predictions(smooth_mod) %>%
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(y = pred), color = "red")

train_df %>%
  add_predictions(wiggly_mod) %>%
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(y = pred), color = "red")
```

```{r}
train_df %>% 
  gather_predictions(linear_mod, smooth_mod, wiggly_mod) %>% 
  mutate(model = fct_inorder(model)) %>% 
  
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  geom_line(aes(y = pred), color = "red") + 
  facet_wrap(~model)
```

Calculate root mean square error where larger values are worse

```{r}
rmse(linear_mod, test_df)
rmse(smooth_mod, test_df)
rmse(wiggly_mod, test_df)
```

We are interested in the model that will do better on the test dataset. The training dataset is the one where you put in too much stuff. Putting more stuff into the training dataset makes the rmse decrease. 

## Do this all using modelr

crossv_mc generates test-training pairs for cross-validation 

```{r}
cv_df = 
  crossv_mc(nonlin_df, 100) 
```

one note about resample

why are my datasets the same even after changing the number in [[]]

```{r}
cv_df %>% pull(train) %>% .[[1]] %>% as_tibble
```

```{r}
cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

try fitting the linear model to all of these...

```{r}
cv_df = 
  cv_df %>% 
  mutate(linear_mods  = map(train, ~lm(y ~ x, data = .x)),
         smooth_mods  = map(train, ~mgcv::gam(y ~ s(x), data = .x)),
         wiggly_mods  = map(train, ~gam(y ~ s(x, k = 30), sp = 10e-6, data = .x))) %>% 
  mutate(rmse_linear = map2_dbl(linear_mods, test, ~rmse(model = .x, data = .y)),
         rmse_smooth = map2_dbl(smooth_mods, test, ~rmse(model = .x, data = .y)),
         rmse_wiggly = map2_dbl(wiggly_mods, test, ~rmse(model = .x, data = .y)))
```

visualize this

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```
